{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Task - 1 Write a function that takes OfferDetails as input, and returns FaceValue as output\n",
    "- Task - 2 Write a function that takes OfferDetails as input, and returns Product as output (Product can be single or array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We have to extract FaceValue from the offerdetails. FaceValue is the savings on the offer , generally a number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('coupons_ner.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(886, 1)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Below represents sample coupon data for a retailer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Save $2.00 ONE Downy Liquid Fabric Conditioner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Save $2.00 ONE Tide PODS OR Tide Power PODS (e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Save $2.00 ONE Tide Laundry Detergent (exclude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SAVE $1.00 ON TWO when you buy TWO BOXES (8.9 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$3.00 OFF when you purchase any THREE (3) Pepp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SAVE $1.11 when you buy any ONE (1) Familly Si...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SAVE $1.00 ON TWO when you buy TWO PACKAGES an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Save $1.00 on any TWO (2) Sargento® Natural Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>$0.65 OFF On Any ONE (1) Oikos Greek Yogurt Cu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$2.00 OFF ONE (1) SMALL bag of Eight O'Clock® ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Save $0.50 ONE Tide Simply Laundry Detergent 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SAVE $1.00 ON TWO when you buy TWO BOXES any f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>$0.50 OFF on ONE (1) Frigo® Cheese Heads® 8ct ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Save $0.50 off ONE (1) jar of Pace® Salsa or P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>$1.00 OFF on any THREE (3) noosa® yoghurts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Save $1.00 on any ONE (1) Gardein™ Frozen Item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Save $1.00 ONE Gain Flings 12 ct TO 26 ct OR G...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Save $0.50 on any ONE (1) pack of Energizer® B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SAVE $2.00 on TWO (2) Purina® Beggin®, Busy® o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Save $0.50 on any one (1) Pine-Sol® product, 4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SAVE $1.00 ON ONE when you buy ONE PACKAGE any...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SAVE $1.25 on any ONE (1) crunchy Crunchmaster...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Save $2.00 ONE Dreft Newborn Laundry Detergent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>$1.00 OFF any THREE (3) Happy Baby Organics &amp;a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Save $1.00 on any ONE (1) Udi's® Frozen Item</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Save $1.00 ONE Downy Liquid Fabric Conditioner...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Save $1.00 ONE Gain Liquid Fabric Softener 48 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>$1.00 OFF on any ONE (1) Tillamook® Ice Cream ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Save $1.00 on Any ONE (1) BENADRYL® 20ct, 24ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Save $1.00 ONE Oral-B Glide Manual Floss, Flos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>SAVE $2.50 on ONE Fixodent Cleanser Tabs when ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>SAVE $1.00 on Any ONE (1) BENADRYL® 20ct, 24ct...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>$5.00 OFF on any ONE (1) Osteo Bi-Flex® produc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>SAVE $3.00 ONLY On Colgate® Optic White® Renew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>SAVE $5.00 on TWO Pantene Pro-V Ingredients OR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>$4.00 OFF on ONE (1) Allegra® Allergy 24ct or ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>SAVE $3.00 ONE (1) Nexium® 24HR 28ct or larger</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>$0.50 OFF ONE (1) bag of Bridgford Sweet Baby ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>SAVE $1.00 on ONE (1) NIVEA® Body Wash 20 fl. oz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>SAVE $3.00 off any ONE (1) Children's Claritin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>SAVE $0.50 On One (1) Can of Fix-a-Flat® 16 oz.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>SAVE 75¢ when you buy ONE (1) bubly™ sparkling...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>SAVE $2.00 off any ONE (1) Banana Boat® or Haw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>SAVE $3.00 off ONE (1) Claritin® 20ct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>$4.00 OFF on any ONE (1) 12ct. multipack SHEBA...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>$1.00 OFF any ONE (1) FINISH® Automatic Dishwa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>SAVE $1.00 ONE Oral-B Special Care Oral Rinse ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>SAVE $0.50 off ONE (1) MAXWELL HOUSE Iced Coff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>SAVE $1.00 on ANY ONE (1) bag of NEW Kingsford...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>SAVE $2.00 when you spend $6.00 on any Degree ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>SAVE $2.00 when you spend $6 on any Quaker Pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>SAVE $1.00 when you buy ONE (1) 28 oz.TRESemmé...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>SAVE $1.00 on DGH Auto Spray Refills Twin Packs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>SAVE $3.00 when you spend $10 on any Bayer Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>BUY TWO GET ONE Buy ONE (1) SOUR PATCH KIDS or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>SAVE $2.00 when you buy $7 worth of participat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>SAVE $5.00 on any Gain scented purchase of $30...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>SAVE $1.00 when you buy any ONE (1) NEW AXE pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>BUY TWO GET ONE Buy ONE (1) CHIPS AHOY! Cookie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>SAVE $2.00 when you spend $6 on all Suave® pro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>886 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     0\n",
       "0    Save $2.00 ONE Downy Liquid Fabric Conditioner...\n",
       "1    Save $2.00 ONE Tide PODS OR Tide Power PODS (e...\n",
       "2    Save $2.00 ONE Tide Laundry Detergent (exclude...\n",
       "3    SAVE $1.00 ON TWO when you buy TWO BOXES (8.9 ...\n",
       "4    $3.00 OFF when you purchase any THREE (3) Pepp...\n",
       "5    SAVE $1.11 when you buy any ONE (1) Familly Si...\n",
       "6    SAVE $1.00 ON TWO when you buy TWO PACKAGES an...\n",
       "7    Save $1.00 on any TWO (2) Sargento® Natural Ch...\n",
       "8    $0.65 OFF On Any ONE (1) Oikos Greek Yogurt Cu...\n",
       "9    $2.00 OFF ONE (1) SMALL bag of Eight O'Clock® ...\n",
       "10   Save $0.50 ONE Tide Simply Laundry Detergent 3...\n",
       "11   SAVE $1.00 ON TWO when you buy TWO BOXES any f...\n",
       "12   $0.50 OFF on ONE (1) Frigo® Cheese Heads® 8ct ...\n",
       "13   Save $0.50 off ONE (1) jar of Pace® Salsa or P...\n",
       "14          $1.00 OFF on any THREE (3) noosa® yoghurts\n",
       "15      Save $1.00 on any ONE (1) Gardein™ Frozen Item\n",
       "16   Save $1.00 ONE Gain Flings 12 ct TO 26 ct OR G...\n",
       "17   Save $0.50 on any ONE (1) pack of Energizer® B...\n",
       "18   SAVE $2.00 on TWO (2) Purina® Beggin®, Busy® o...\n",
       "19   Save $0.50 on any one (1) Pine-Sol® product, 4...\n",
       "20   SAVE $1.00 ON ONE when you buy ONE PACKAGE any...\n",
       "21   SAVE $1.25 on any ONE (1) crunchy Crunchmaster...\n",
       "22   Save $2.00 ONE Dreft Newborn Laundry Detergent...\n",
       "23   $1.00 OFF any THREE (3) Happy Baby Organics &a...\n",
       "24        Save $1.00 on any ONE (1) Udi's® Frozen Item\n",
       "25   Save $1.00 ONE Downy Liquid Fabric Conditioner...\n",
       "26   Save $1.00 ONE Gain Liquid Fabric Softener 48 ...\n",
       "27   $1.00 OFF on any ONE (1) Tillamook® Ice Cream ...\n",
       "28   Save $1.00 on Any ONE (1) BENADRYL® 20ct, 24ct...\n",
       "29   Save $1.00 ONE Oral-B Glide Manual Floss, Flos...\n",
       "..                                                 ...\n",
       "856  SAVE $2.50 on ONE Fixodent Cleanser Tabs when ...\n",
       "857  SAVE $1.00 on Any ONE (1) BENADRYL® 20ct, 24ct...\n",
       "858  $5.00 OFF on any ONE (1) Osteo Bi-Flex® produc...\n",
       "859  SAVE $3.00 ONLY On Colgate® Optic White® Renew...\n",
       "860  SAVE $5.00 on TWO Pantene Pro-V Ingredients OR...\n",
       "861  $4.00 OFF on ONE (1) Allegra® Allergy 24ct or ...\n",
       "862     SAVE $3.00 ONE (1) Nexium® 24HR 28ct or larger\n",
       "863  $0.50 OFF ONE (1) bag of Bridgford Sweet Baby ...\n",
       "864  SAVE $1.00 on ONE (1) NIVEA® Body Wash 20 fl. oz.\n",
       "865  SAVE $3.00 off any ONE (1) Children's Claritin...\n",
       "866    SAVE $0.50 On One (1) Can of Fix-a-Flat® 16 oz.\n",
       "867  SAVE 75¢ when you buy ONE (1) bubly™ sparkling...\n",
       "868  SAVE $2.00 off any ONE (1) Banana Boat® or Haw...\n",
       "869              SAVE $3.00 off ONE (1) Claritin® 20ct\n",
       "870  $4.00 OFF on any ONE (1) 12ct. multipack SHEBA...\n",
       "871  $1.00 OFF any ONE (1) FINISH® Automatic Dishwa...\n",
       "872  SAVE $1.00 ONE Oral-B Special Care Oral Rinse ...\n",
       "873  SAVE $0.50 off ONE (1) MAXWELL HOUSE Iced Coff...\n",
       "874  SAVE $1.00 on ANY ONE (1) bag of NEW Kingsford...\n",
       "875  SAVE $2.00 when you spend $6.00 on any Degree ...\n",
       "876  SAVE $2.00 when you spend $6 on any Quaker Pro...\n",
       "877  SAVE $1.00 when you buy ONE (1) 28 oz.TRESemmé...\n",
       "878    SAVE $1.00 on DGH Auto Spray Refills Twin Packs\n",
       "879  SAVE $3.00 when you spend $10 on any Bayer Con...\n",
       "880  BUY TWO GET ONE Buy ONE (1) SOUR PATCH KIDS or...\n",
       "881  SAVE $2.00 when you buy $7 worth of participat...\n",
       "882  SAVE $5.00 on any Gain scented purchase of $30...\n",
       "883  SAVE $1.00 when you buy any ONE (1) NEW AXE pr...\n",
       "884  BUY TWO GET ONE Buy ONE (1) CHIPS AHOY! Cookie...\n",
       "885  SAVE $2.00 when you spend $6 on all Suave® pro...\n",
       "\n",
       "[886 rows x 1 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some includes SAVE or Save\n",
    "# Includes $ and ¢\n",
    "# Includes OFF\n",
    "pattern = r'^(?:(?:Save|SAVE) )?(\\$?(?:\\d+)(?:\\.\\d+)?¢?)(?: OFF)?'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fun1(data):\n",
    "    '''Function to extract FaceValue'''\n",
    "    FaceValue = []\n",
    "    for _, item in data[0].iteritems():\n",
    "        FaceValue.append(re.findall(pattern, item)) #find the pattern\n",
    "    return FaceValue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each offerdetails we extract FAceValue\n",
    "FaceValue = fun1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the offerdetails which don't include FaceValue as describes by the above pattern\n",
    "empty_index = []\n",
    "for i, ele in enumerate(FaceValue):\n",
    "    if not ele:\n",
    "        empty_index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "308"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(empty_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Total 308 product details are without facevalue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "270    Osteo Bi-Flex® on any ONE (1) Osteo Bi-Flex® p...\n",
       "271        CLIF BAR® on any ONE (1) CLIF® Bar Multipack.\n",
       "272    BENADRYL® on Any ONE (1) BENADRYL® 20ct, 24ct ...\n",
       "273    Claritin® off any ONE (1) Claritin® Cool Mint ...\n",
       "274    Claritin-D® off any ONE (1) Claritin-D® 15ct o...\n",
       "275    Claritin® off any ONE (1) Children's Claritin®...\n",
       "276    Claritin® off any ONE (1) Children's Claritin®...\n",
       "277     Ensure® on Any TWO (2) Ensure Multi-Pack Shakes.\n",
       "278    Aleve® on any ONE (1) Aleve® or Aleve®PM produ...\n",
       "279    Adult ZYRTEC® when you buy ONE (1) Adult ZYRTE...\n",
       "280          Florastor on any ONE (1) Florastor product.\n",
       "281    Allegra® on ONE (1) Allegra® Allergy 24ct or l...\n",
       "282                            Dixie Tableware 40-94-ct.\n",
       "283    Kingsford Match Light or Charcoal... 12-16-lb....\n",
       "284    Pabst Blue Ribbon on ONE (1) Pabst Blue Ribbon...\n",
       "285    Tide ONE Tide Laundry Detergent 37 oz TO 50 oz...\n",
       "286    Tide ONE Tide PODS 16 ct OR 12 ct (excludes Ti...\n",
       "287    Chinet® Cut Crystal® Buy TWO (2) Chinet® Cut C...\n",
       "288    Gain ONE Gain Flings 16 ct OR 14 ct OR 12 ct O...\n",
       "289    Gain ONE Gain Liquid Fabric Softener 48 ld OR ...\n",
       "290       Raid® any ONE (1) Raid® Wasp & Hornet Product.\n",
       "291               OFF!® any ONE (1) OFF!® brand product.\n",
       "292    Raid® on any ONE (1) Raid® Essential Oils Prod...\n",
       "293    OFF!® on any ONE (1) OFF!® Product (Excludes C...\n",
       "294                         Tillamook Ice Cream 1.75-qt.\n",
       "295                          Popsicle Novelties 9-18-ct.\n",
       "296    Pepperidge Farm Turnovers 12.5-oz. or 19.6-oz....\n",
       "297    Signature SELECT Frozen Dessert 8-9.87-oz. Lim...\n",
       "298          Signature SELECT Ice Cream 1.5-qt. Limit 1.\n",
       "299    Tillamook® Ice Cream on any TWO (2) Tillamook®...\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].iloc[270:300]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above are some offerdetails which dont include FAceValue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In this task we have to extract product names from offer details.\n",
    "- Product - Can be a single value or an array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NER model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- For this task we have to build product corpus manually and from that we have to build NER model which recognizes product as P(Product) and remaining words as O (Other).\n",
    "- We first extract all words from offerdetails.\n",
    "- We will find unique words to label.\n",
    "- Manually we will label the words (P/O) in a text file- words.txt.\n",
    "- To label words we assume some notations like, ®, ™ which are mostlly in product names.\n",
    "- Some word along with numbers like 8-9.87-oz, 5.7-6.50 , lb, liter, gallon which are not in product names.\n",
    "- Some brand names like huggies, Hershey's, Tide, Pulsar, etc\n",
    "- After manual labelling we will use many-to-many LSTM based architecture in which offerdeatails is input and tags for each word is output.\n",
    "- We will use Adam optimizer, sparse_categorical_cross_entropy as loss function.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Find Unique words from offer details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.layers import LSTM, GRU, Dense, Input, Embedding, Bidirectional\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = []\n",
    "for _, ele in data[0].iteritems():\n",
    "    for word in ele.split(' '):\n",
    "        words.append(word.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15747"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_words = list(set(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2351"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write words in to text file\n",
    "with open('words.txt', 'w') as f:\n",
    "    for item in unique_words:\n",
    "        f.write(\"%s\\n\" % item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get words and tags from word.text\n",
    "u_words = []\n",
    "u_tags = []\n",
    "with open('words.txt','r') as f:\n",
    "    for line in f:\n",
    "        lst = line.split(' ')\n",
    "        u_words.append(line.split(' ')[0])\n",
    "        u_tags.append(line.split(' ')[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_tagss = list(set(u_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2351"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2351"
      ]
     },
     "execution_count": 443,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(u_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dictionary for word and associated tags\n",
    "word_tag_dictionary = dict(zip(u_words, u_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tags and number dictionary\n",
    "# Her P is for product, O/o is for Other and '' for ''\n",
    "tags = ['', 'P\\n', 'O\\n', 'o\\n']\n",
    "tag_nums = [0, 1, 2, 3]\n",
    "tags_to_numbers = dict(zip(tags, tag_nums))\n",
    "numbers_to_tags = dict(zip(tag_nums, tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_numbers = {w: i for i, w in enumerate(unique_words)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create output Y for tags associated with words in input offerdetails\n",
    "data_y = []\n",
    "for row in data[0]:\n",
    "    label = []\n",
    "    for ele in row.split(' '):\n",
    "        if ele.lower() in word_tag_dictionary:\n",
    "            label.append(tags_to_numbers[word_tag_dictionary[ele.lower()]])\n",
    "    data_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input X for numbers associated with words in offerdetails\n",
    "data_x = []\n",
    "for row in data[0]:\n",
    "    label = []\n",
    "    for ele in row.split(' '):\n",
    "        if ele.lower() in  word_to_numbers and ele.lower() != '':\n",
    "            label.append(word_to_numbers[ele.lower()])\n",
    "    data_x.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FInd max len from all input\n",
    "length_x = [len(ele) for ele in data_x]\n",
    "maxlen = max(length_x)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad X and Y with maxlen\n",
    "X = pad_sequences(maxlen=maxlen, sequences=data_x, padding=\"post\")\n",
    "y = pad_sequences(maxlen=maxlen, sequences=data_y, padding=\"post\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Split Train and TEst data using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(708, 77) (178, 77) (708, 77) (178, 77)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_len = len(u_words) \n",
    "embedding_dim = 64\n",
    "dense_units = 4\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 502,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    tf.keras.backend.clear_session()\n",
    "    input_layer = Input(shape=(maxlen,), name=\"input_layer\")\n",
    "    \n",
    "    x_embedd = Embedding(input_dim=word_len, output_dim=embedding_dim, input_length=maxlen, \n",
    "                    mask_zero=True, \n",
    "                    embeddings_initializer=tf.keras.initializers.RandomNormal(mean=0, stddev=1, seed=23),\n",
    "                     name=\"Embedding_layer\")(input_layer)\n",
    "    \n",
    "    '''x_bilstm = Bidirectional(LSTM(units=20, activation='tanh', return_sequences=True, recurrent_activation='sigmoid', use_bias=True, \n",
    "                 kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n",
    "                 recurrent_initializer=tf.keras.initializers.orthogonal(seed=54),\n",
    "                 bias_initializer=tf.keras.initializers.zeros(), name=\"BiLSTM_layer\"))(x_embedd)\n",
    "    \n",
    "    x_lstm = LSTM(units=20, activation='tanh', return_sequences=True, recurrent_activation='sigmoid', use_bias=True, \n",
    "                 kernel_initializer=tf.keras.initializers.glorot_uniform(seed=26),\n",
    "                 recurrent_initializer=tf.keras.initializers.orthogonal(seed=54),\n",
    "                 bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM_layer\")(x_bilstm)'''\n",
    "    \n",
    "    x_out = Dense(dense_units, activation=None, kernel_initializer=tf.keras.initializers.glorot_uniform(seed=45),\n",
    "                  name=\"output_layer\")(input_layer)\n",
    "    \n",
    "    basic_lstm_model = Model(inputs=input_layer, outputs=x_out, name=\"basic_lstm_model\")\n",
    "    \n",
    "    return basic_lstm_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 503,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     (None, 77)                0         \n",
      "_________________________________________________________________\n",
      "output_layer (Dense)         (None, 4)                 312       \n",
      "=================================================================\n",
      "Total params: 312\n",
      "Trainable params: 312\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define optimizer\n",
    "def optimizer():\n",
    "    return tf.keras.optimizers.Adam()\n",
    "  \n",
    "# Define Loss function\n",
    "def loss(labels, logits):\n",
    "  loss_ = tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "  return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 708 samples, validate on 178 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "logits and labels must have the same first dimension, got logits shape [32,4] and labels shape [2464]\n\t [[{{node loss/output_layer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-506-afaef8c8fbe9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m           validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 329\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    330\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3074\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3076\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/framework/errors_impl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type_arg, value_arg, traceback_arg)\u001b[0m\n\u001b[1;32m    526\u001b[0m             \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m             \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc_api\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_Message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 528\u001b[0;31m             c_api.TF_GetCode(self.status.status))\n\u001b[0m\u001b[1;32m    529\u001b[0m     \u001b[0;31m# Delete the underlying status object from memory otherwise it stays alive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;31m# as there is a reference to status from this from the traceback due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: logits and labels must have the same first dimension, got logits shape [32,4] and labels shape [2464]\n\t [[{{node loss/output_layer_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits}}]]"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, batch_size=32, epochs=2, validation_data=(X_test, y_test), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 464,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(708, 77)"
      ]
     },
     "execution_count": 464,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(708, 77)"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.13.1'"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.VERSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
